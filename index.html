<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
    <!--meta data-->
	<meta name="google-site-verification" content="-rMHxo-cl0Jew02VvS79wZX7LGscTuFAdqKXFv1OWYY" />
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="keywords" content="Bin Wang, Northwestern University, NWU, NU, 美国西北大学, ShanghaiTech Unviersity, Shanghaitech, 上海科技大学">
    <meta name="description" content="Bin Wang's Homepage">
	<!-- <meta name="viewport" content="width=device-width, initial-scale=1.0"> -->
	
    <link rel="stylesheet" href="./css/jemdoc.css" type="text/css">
    <style type="text/css">
	</style>
    <title>Bin Wang - Homepage</title>
<!-- 	<link rel="shortcut icon" href="./avatar/icon/NU.jpg"> -->
<!--     <link rel="apple-touch-icon" sizes="180x180" href="./avatar/icon/NU.jpg"> -->
<!--     <link rel="icon" type="image/png" sizes="16x16" href="./avatar/icon/NU.jpg"> -->
<!--     <link rel="manifest" href="./avatar/icon/NU.jpg"> -->
<!--     <link rel="mask-icon" href="./avatar/icon/NU.jpg" color="#5bbad5"> -->
    <meta name="theme-color" content="#ffffff">
</head>

<body>

<div id="layout-content" style="margin-top: 25px">

    <table style="width: 100%; table-layout: fixed;">
        <tbody>
            <tr>
                <td width="65%" valign="top" style="padding-right: 20px;">
                    <div style="font-family: Verdana, sans-serif;">
                        <b style="font-size: 2.5em; display: block;">Bin Wang (王斌)</b>
                        <br><br>
                        <span style="font-size: 1.5em;">Northwestern University</span>
                        <br><br>
                        <span style="font-size: 1.1em;">Email: bin.wang@northwestern.edu</span>
                        <br><br>
                        <div style="font-size: 1.1em;">
                            <a href="https://scholar.google.com/citations?user=XWNsMhYAAAAJ&hl=en" target="_blank">Google Scholar</a> /
                            <a href="https://github.com/ukaukaaaa" target="_blank">Github</a> /
                            <a href="https://www.linkedin.com/in/bin-wang-7baa41214/" target="_blank">LinkedIn</a> /
                            <a href="./Bin Wang CV.pdf" target="_blank">Resume</a>
                        </div>
                    </div>
                </td>
                
                <td width="35%" valign="top" style="text-align: center;">
                    <img height="320" id="photo" style="border-radius: 10px; padding: 10px;" src="avatar/icon'.jpg" alt="Bin Wang Photo">
                </td>
            </tr>
        </tbody>
    </table>
</div>


	    
<h2>About Me</h2>
<p>
    I am currently a third-year Ph.D. student at 
    <a href="https://www.northwestern.edu/" target="_blank">Northwestern University</a> in Electrical and Computer Engineering, supervised by 
    Prof. <a href="https://scholar.google.com/citations?user=9LUdPM4AAAAJ&hl=en" target="_blank">Ulas Bagci</a> and 
    Prof. <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/katsaggelos-aggelos.html" target="_blank">Aggelos K. Katsaggelos</a>.
    I earned my B.Eng degree in computer science from 
    <a href="https://www.shanghaitech.edu.cn/eng/" target="_blank">ShanghaiTech University</a> in 2022, where I worked with 
    Prof. <a href="https://scholar.google.com/citations?hl=en&user=v6VYQC8AAAAJ" target="_blank">Dinggang Shen</a>.
</p>

	    
<h2>Research Interests</h2>
<ul style="list-style: none; padding: 0 0 0 20px;">
    <li style="margin-bottom: 15px;"><strong>Human-centered AI:</strong> interactive segmentation, tracking, editing (image/video), user prompt fusion.</li>
    <li style="margin-bottom: 15px;"><strong>Eye Tracking:</strong> human visual attention and perception understanding.</li>
    <li style="margin-bottom: 15px;"><strong>Multimodal Learning:</strong> vision-language models, multimodal fusion.</li>
</ul>




<h2>News</h2>
<ul style="list-style: none; padding: 0;">
    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[02/2025]</strong> 
        <span>One paper is accepted by <a href="https://cvpr.thecvf.com" target="_blank" style="text-decoration: none;">CVPR 2025</a>!</span>
    </li>
    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[01/2025]</strong> 
        <span>One paper is accepted by <a href="https://iclr.cc/" target="_blank" style="text-decoration: none;">ICLR 2025</a>!</span>
    </li>

    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[11/2024]</strong> 
        <span>Gave an invited talk, "EyeSee: Utilize Eye Tracking to Improve Medical Image Analysis", at <a href="https://www.mipg.upenn.edu/" target="_blank" style="text-decoration: none;">UPenn MIPG</a>.</span>
    </li>
	
    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[06/2024]</strong> 
        <span>Started a summer internship at <a href="https://www.linkedin.com/company/uii-america-inc/mycompany/" target="_blank" style="text-decoration: none;">United Imaging Intelligence, America</a>, under the guidance of <a href="https://wuziyan.com" target="_blank" style="text-decoration: none;">Ziyan Wu</a>.</span>
    </li>
    
    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[05/2024]</strong> 
        <span>Honored with the <a href="https://mips.synchrosystems.com" target="_blank" style="text-decoration: none;">MIPS Scholar Award</a>.</span>
    </li>
    
    <li style="margin-bottom: 20px; border-left: 4px solid #000; padding-left: 10px;">
        <strong style="font-size: 1em;">[04/2024]</strong> 
        <span>Gave an invited talk, <a href="https://www.youtube.com/watch?v=gZ3bnQLpXwk&t=1912s" target="_blank" style="text-decoration: none;">"Radiologist-centered AI with Eye Tracking Techniques"</a>, at <a href="https://www.youtube.com/@stanfordmedai" target="_blank" style="text-decoration: none;">Stanford MedAI</a>.</span>
    </li>
</ul>


	    

<h2>Selected Publications</h2>
<table border="0" width="100%">
    <tbody>
        <tr>
            <td>
                <br>
            </td>
        </tr>

	    
	 <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/OIS/logo.gif" alt="">
                </div>
            </td>
            <td>
                <pt>Order-aware Interactive Segmentation</pt>
                <br>
        	<span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Anwesa Choudhuri, Meng Zheng, Zhongpai Gao, Benjamin Planche, Andong Deng, Qin Liu, Terrence Chen, Ulas Bagci, Ziyan Wu.<br>
		<span style="color:darkred;">ICLR 2025</span><br>
                [<a href="https://arxiv.org/abs/2410.12214" target="_blank">Arxiv</a>]&nbsp;
	        [<a href="https://ukaukaaaa.github.io/projects/OIS/index.html" target="_blank">Project Page</a>]&nbsp;
	        [<a href="https://www.youtube.com/playlist?list=PL9M9xNKC8MORxKgPlFlC9_htqxRS09USw" target="_blank">Demo</a>]&nbsp;
	        [<a href="https://notebooklm.google.com/notebook/efde2080-a23c-43e4-882d-83cb4ebb4cfd/audio" target="_blank">NotebookLM</a>]&nbsp;
		


	<!-- GazeSAM: What You See is What You Segment -->
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/gazegnn/logo.png" alt="">
                </div>
            </td>
            <td>
                <pt>GazeGNN: A Gaze-Guided Graph Neural Network for Chest X-ray Classification</pt>
                <br>
                <span style="text-decoration: underline; font-weight: bold;">Bin Wang*</span>, Hongyi Pan*, Armstrong Aboah, Zheyuan Zhang, Elif Keles, Drew Torigian, Baris Turkbey, Elizabeth Krupinski, Jayaram Udupa, Ulas Bagci.<br>
		<span style="color:darkred;">WACV 2024 [Early Accept]</span><br>
                [<a href="https://arxiv.org/abs/2305.18221" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/ukaukaaaa/GazeGNN" target="_blank">Code</a>]&nbsp;
                <!--  <p style="color:red;font-size:60%;">  </p>
                    <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;">Best Paper Honorable Mention Award</a></em></p> -->
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>


	    

        <!-- GazeSAM: What You See is What You Segment -->
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/gazesam/icon.gif" alt="">
                </div>
            </td>
            <td>
                <pt>GazeSAM: Interactive Image Segmentation with Eye Gaze and Segment Anything Model</pt>
                <br>
                <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Armstrong Aboah, Zheyuan Zhang, Ulas Bagci.<br>
		<span style="color:darkred;">NeurIPS Workshop 2023</span><br>    
                [<a href="https://openreview.net/pdf?id=hJ5DREWdjs" target="_blank">Paper</a>]&nbsp;
                [<a href="https://github.com/ukaukaaaa/GazeSAM" target="_blank">Code</a>]&nbsp;
                [<a href="https://ukaukaaaa.github.io/projects/gazesam/gazesam.html" target="_blank">Project Page</a>]&nbsp;
<!-- 		[<a href="https://youtu.be/wRuhTUdXWEk" target="_blank">Youtube</a>]&nbsp; -->
                <!--  <p style="color:red;font-size:60%;">  </p>
                    <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;">Best Paper Honorable Mention Award</a></em></p> -->
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>


        <!-- Deep learning-based Head and Neck Radiotherapy Planning Dose Prediction via Beam-wise Dose Decomposition -->
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/beam/logo.png" alt="">
                </div>
            </td>
            <td>
                <pt>Deep learning-based Head and Neck Radiotherapy Planning Dose Prediction via Beam-wise Dose Decomposition</pt>
                <br>
                <span style="text-decoration: underline; font-weight: bold;">Bin Wang*</span>, Lin Teng*, Lanzhuju Mei, Zhiming Cui, Xuanang Xu, Qianjin Feng, Dinggang Shen.<br>
                <span style="color:darkred;">MICCAI 2022</span><br>  
                [<a href="./projects/beam/beampaper.pdf" target="_blank">Paper</a>]&nbsp;
                [<a href="https://github.com/ukaukaaaa/BeamDosePrediction" target="_blank">Code</a>]&nbsp;
                <!--  <p style="color:red;font-size:60%;">  </p>
                    <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;">Best Paper Honorable Mention Award</a></em></p> -->
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>
		    

            <!-- Globally Convergent Algorithms For Learning Multivariate Generalized Gaussian Distributions -->
            <tr>
                <td>
                    <div align="center">
                        <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/mggd/mggdicon.png" alt="">
                    </div>
                </td>
                <td>
                    <pt>Globally Convergent Algorithms For Learning Multivariate Generalized Gaussian Distributions</pt>
                    <br>
                    <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Huanyu Zhang, Ziping Zhao, Ying Sun.<br>
                    <span style="color:darkred;">SSP 2021</span><br>  
                    [<a href="./projects/mggd/mggdpaper.pdf" target="_blank">Paper</a>]&nbsp;
                    [<a href="https://github.com/ukaukaaaa/MGGD" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>
	    
 	* Equal contribution
        </tbody>
    </table>


<h2>Other Publications</h2>
<table border="0" width="100%">
    <tbody>
        <tr>
            <td>
                <br>
            </td>
        </tr>



        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/seq2timeicon.png" alt="">
                </div>
            </td>
            <td>
                <pt>Seq2Time: Sequential Knowledge Transfer for Video LLM Temporal Grounding</pt>
                <br>
                Andong Deng, Zhongpai Gao, Anwesa Choudhuri, Benjamin Planche, Meng Zheng, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Terrence Chen, Chen Chen, Ziyan Wu.<br>
		<span style="color:darkred;">CVPR 2025</span><br>
                [<a href="https://arxiv.org/pdf/2411.16932" target="_blank">Paper</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>

	    
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/tmigazessl/logo.png" alt="">
                </div>
            </td>
            <td>
                <pt>Improving Self-Supervised Medical Image Pre-Training by Early Alignment with Human Eye Gaze Information</pt>
                <br>
                Sheng Wang, Zihao Zhao, Zhenrong Shen, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Qian Wang, Dinggang Shen.<br>
		<span style="color:darkred;">IEEE Transactions on Medical Imaging (TMI) 2025</span><br>
                [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10839445" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/zhaozh10/McGIP" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>


        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/emit-diff/emit-diffcover.png" alt="">
                </div>
            </td>
            <td>
                <pt>DiffBoost: Enhancing Medical Image Segmentation via Text-Guided Diffusion Model</pt>
                <br>
		Zheyuan Zhang, Lanhong Yao, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Debesh Jha, Gorkem Durak, Elif Keles, Alpay Medetalibeyoglu, Ulas Bagci.<br>
		<span style="color:darkred;">IEEE Transactions on Medical Imaging (TMI) 2025</span><br>
                [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10804854" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/NUBagciLab/DiffBoost" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>
	    
<!-- MIA Dose -->
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/miadose/logo.png" alt="">
                </div>
            </td>
            <td>
                <pt>Beam-wise dose composition learning for head and neck cancer dose prediction in radiotherapy</pt>
                <br>
                Lin Teng*, <span style="text-decoration: underline; font-weight: bold;">Bin Wang*</span>, Xuanang Xu*, Jiadong Zhang, Lanzhuju Mei, Qianjin Feng, Dinggang Shen.<br>
		<span style="color:darkred;">Medical Image Analysis 2024</span><br>
                [<a href="https://www.sciencedirect.com/science/article/abs/pii/S1361841523003055" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/TL9792/BDCLDosePrediction" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>
		    

	 <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/miccai2024icon.png" alt="">
                </div>
            </td>
            <td>
                <pt>Gaze-directed Vision GNN for Mitigating Shortcut Learning in Medical Image</pt>
                <br>
                Shaoyuan Wu, Xiao Zhang, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Zhuo Jin, Hansheng Li, Jun Feng.<br>
		<span style="color:darkred;">MICCAI 2024</span><br>
                [<a href="https://arxiv.org/pdf/2406.14050" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/SX-SS/GD-ViG" target="_blank">Code</a>]&nbsp;
                <!--  <p style="color:red;font-size:60%;">  </p>
                    <p style="color:red;font-size:100%;"> <em><a href="https://blog.siggraph.org/2022/07/siggraph-2022-technical-papers-awards-best-papers-and-honorable-mentions.html/" target="_blank" style="color:#FF0000;">Best Paper Honorable Mention Award</a></em></p> -->
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>

	    
	 <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/fedicassp2024/logo.png" alt="">
                </div>
            </td>
            <td>
                <pt>Domain Generalization with Fourier Transform and Soft Thresholding</pt>
                <br>
                Hongyi Pan, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Zheyuan Zhang, Xin Zhu, Debesh Jha, Ahmet Enis Cetin, Concetto Spampinato, Ulas Bagci.<br>
		<span style="color:darkred;">ICASSP 2024</span><br>
                [<a href="https://arxiv.org/pdf/2309.09866.pdf" target="_blank">Paper</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>



        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/csu/csuicon.png" alt="">
                </div>
            </td>
            <td>
                <pt>Domain generalization with correlated style uncertainty</pt>
                <br>
                Zheyuan Zhang, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Debesh Jha, Ugur Demir, Ulas Bagci.<br>
		<span style="color:darkred;">WACV 2024 [Early Accept]</span><br>
                [<a href="https://arxiv.org/pdf/2212.09950.pdf" target="_blank">Paper</a>]&nbsp;
	        [<a href="https://github.com/ukaukaaaa/GazeGNN" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>



        <!-- yolo -->
        <tr>
            <td>
                <div align="center">
                    <img width="300" style="padding: 0pt 10pt 0pt 0pt" src="./projects/yolo/yolocover.png" alt="">
                </div>
            </td>
            <td>
                <pt>Real-time multi-class helmet violation detection using few-shot data sampling technique and yolov8</pt>
                <br>
                Armstrong Aboah, <span style="text-decoration: underline; font-weight: bold;">Bin Wang</span>, Ulas Bagci, Yaw Adu-Gyamfi.<br>
		<span style="color:darkred;">CVPR Workshop 2023<br> 7th place in 2023 AI City Challenge</span><br>    
                [<a href="https://openaccess.thecvf.com/content/CVPR2023W/AICity/papers/Aboah_Real-Time_Multi-Class_Helmet_Violation_Detection_Using_Few-Shot_Data_Sampling_Technique_CVPRW_2023_paper.pdf" target="_blank">Paper</a>]&nbsp;
                [<a href="https://github.com/aboah1994/few-shot-Video-Data-Sampling" target="_blank">Code</a>]&nbsp;
                </td>
            </tr>
            <tr>
                <td>
                    <br>
                </td>
            </tr>

 	* Equal contribution
        </tbody>
    </table>

	    
<h2>Reviewer Service</h2>
<ul style="list-style-type: none; padding-left: 0;">
    <li style="margin-bottom: 10px;">
        <strong>Conferences:</strong> MICCAI2025, CHI2025, MICCAI2024, NeurIPS2023
    </li>
    <li style="margin-bottom: 10px;">
        <strong>Journals:</strong> Transactions on Image Processing (TIP), Transactions on Medical Imaging (TMI), Transactions on Consumer Electronics, Journal of Biomedical and Health Informatics (JBHI), Medical Physics, Journal of Imaging Informatics in Medicine
    </li>
</ul>

		
		
		
<!--         <h4>
            <br> -->
<!-- 		<p><center>
            <div id="clustrmaps-widget" style="width:40%">
      		<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=tsyv7MGlz0-b2EJXyrMtMb3jw0uYDjzhh26o_Msvlo4&cl=ffffff&w=a"></script>
		    <br> -->

		<div style="text-align: center; padding-top: 20px;">
		    Design based on <a href="https://enigma-li.github.io" target="_blank">Changjian Li</a>'s website
		</div>



</body>
</html>
